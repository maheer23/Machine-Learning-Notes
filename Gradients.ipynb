{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Gradients.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNnaXHO94v9I1lnRO+pJZdZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/maheer23/Machine-Learning-Notes/blob/main/Gradients.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rKtQ5mdcg4yH"
      },
      "source": [
        "# PyTorch Fundamentals\n",
        "\n",
        "## Tensors with Gradients\n",
        "\n",
        "### Creating Tensor with Gradients\n",
        "\n",
        "* A Variable wraps a Tensor\n",
        "* Allows accumulation of gradients"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "__UN0g80onDr",
        "outputId": "d8537ed8-0835-48eb-98fe-cf2dae748ee4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import torch\n",
        "\n",
        "a = torch.ones((2, 2), requires_grad=True)\n",
        "a"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 1.],\n",
              "        [1., 1.]], requires_grad=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ctp-Imq9o0X2",
        "outputId": "eca029cc-d9ca-494a-cafc-ef06d819f41f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "a.requires_grad"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dxHkAgCdVN1Z",
        "outputId": "a209171a-b068-4499-8181-b3a63432301e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Not a variable\n",
        "no_gradient = torch.ones(2, 2)\n",
        "\n",
        "no_gradient.requires_grad"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uCXpBEiDhqND"
      },
      "source": [
        "###  Behaves similarly to tensors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BG_xEJV6o-rC",
        "outputId": "5dc677c5-70d4-4206-91ed-0bddfcd7eaf7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "b = torch.ones((2, 2), requires_grad=True)\n",
        "print(a + b)\n",
        "print(torch.add(a, b))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[2., 2.],\n",
            "        [2., 2.]], grad_fn=<AddBackward0>)\n",
            "tensor([[2., 2.],\n",
            "        [2., 2.]], grad_fn=<AddBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qBiY4axcpGkA",
        "outputId": "ae10416a-13b3-4f16-8851-f7dc8e79c5e5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(a * b)\n",
        "print(torch.mul(a, b))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1., 1.],\n",
            "        [1., 1.]], grad_fn=<MulBackward0>)\n",
            "tensor([[1., 1.],\n",
            "        [1., 1.]], grad_fn=<MulBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m1UKfD_0h3Qb"
      },
      "source": [
        "\n",
        "# Manually and Automatically Calculating Gradients.\n",
        "\n",
        "### What exactly is requires_grad?\n",
        "\n",
        "Allows calculation of gradients w.r.t. the variable\n",
        "$$y_i = 5(x_i+1)^2$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oZ_hz15opIJT",
        "outputId": "5b73bd10-2d80-4b82-85f9-1b24dc190b00",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "x = torch.ones(2, requires_grad=True)\n",
        "x"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1., 1.], requires_grad=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-HduW23riDnq"
      },
      "source": [
        "\n",
        "$$y_i\\bigr\\rvert_{x_i=1} = 5(1 + 1)^2 = 5(2)^2 = 5(4) = 20$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7TjeVn3fpMGS",
        "outputId": "e7160f61-89cb-4bf2-986f-08a99718df17",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "y = 5 * (x + 1) ** 2\n",
        "y"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([20., 20.], grad_fn=<MulBackward0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4fjY855IiJJA"
      },
      "source": [
        "### Backward should be called only on a scalar (i.e. 1-element tensor) or with gradient w.r.t. the variable\n",
        "\n",
        "Let's reduce y to a scalar then...\n",
        "$$o = \\frac{1}{2}\\sum_i y_i$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VNmtA0ayA0Gt",
        "outputId": "e595c29a-d4af-48e3-b4fa-0261964a989f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "o = (1/2) * torch.sum(y)\n",
        "o"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(20., grad_fn=<MulBackward0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GPJX0pLQiOgL"
      },
      "source": [
        "\n",
        "$$\\frac{\\partial o}{\\partial x_i} = \\frac{1}{2}[10(x_i+1)]$$\n",
        "$$\\frac{\\partial o}{\\partial x_i}\\bigr\\rvert_{x_i=1} = \\frac{1}{2}[10(1 + 1)] = \\frac{10}{2}(2) = 10$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vr27_qaOiMrM"
      },
      "source": [
        "o.backward()"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kwH-EwesiRBR",
        "outputId": "d91bc38a-97b1-4eb0-f65b-3543e1d7399f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "x.grad"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([10., 10.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3j-lVe9tiR6t",
        "outputId": "1093cd03-cbc1-4a2e-e290-6d193d539b45",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(x.requires_grad)\n",
        "print(y.requires_grad)\n",
        "print(o.requires_grad)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n",
            "True\n",
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fYWiP5M3iZl6"
      },
      "source": [
        "\n",
        "# Summary\n",
        "\n",
        "### Tensor with Gradients\n",
        "* Wraps a tensor for gradient accumulation\n",
        "Gradients\n",
        "\n",
        "### Define original equation\n",
        "* Substitute equation with x values\n",
        "* Reduce to scalar output, o through mean\n",
        "* Calculate gradients with o.backward()\n",
        "* Then access gradients of the x variable through x.grad"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1GzDLoQQiXI_"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}