{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Linear Regression.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMBPorDtkSOdJdpZ+2HOxeu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/maheer23/Machine-Learning-Notes/blob/main/Linear_Regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zGtmTJPAm_Q3"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uUUDPU7VmW_S"
      },
      "source": [
        "### Simple Linear Regression:\n",
        "\n",
        "- Allows to understand the **Relationship** between two **Continuous Variables.**\n",
        "- **Examples:**\n",
        "    - x : Independent Variable\n",
        "        - Weight\n",
        "    - y : Dependent Variable\n",
        "        - Height\n",
        "- $y = \\alpha x + \\beta$\n",
        "\n",
        "### Aim of Linear Regression.\n",
        "\n",
        "- Minimize the distance between the points and the line ($y = \\alpha x + \\beta$).\n",
        "- Adjusting:\n",
        "    - Coefficient: $\\alpha$\n",
        "    - Bias/intercept: $\\beta$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qnikp_OUmW8u"
      },
      "source": [
        "## Building a Linear Regression Model with PyTorch:\n",
        "\n",
        "### Example\n",
        "\n",
        "- Coefficient: \\alpha = 2\n",
        "- Bias/intercept: \\beta = 1\n",
        "- Equation: y = 2x + 1\n",
        "\n",
        " \n",
        "\n",
        "### Building a Toy Dataset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BO4m3NO2mKYy",
        "outputId": "66a88ea5-d56b-4cd9-e9e0-c70a9c2b0a43",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Creating a list of values from 0 to 11\n",
        "x = [i for i in range(11)]\n",
        "x"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YbP22Hnam2Bu"
      },
      "source": [
        "**Convert a list of array into numpy arrays**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1leMcLAWmlIg",
        "outputId": "7d3fea24-376d-4ed3-c2ec-938ed86dd977",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "x_train = np.array(x,dtype= np.float32)\n",
        "\n",
        "x_train.shape"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KYA2lWytnW7j"
      },
      "source": [
        "**Convert into 2D array**\n",
        "If you don't this you will get an error stating you need 2D. Simply just reshape accordingly if you ever face such errors down the road."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "enQt5js8nK5A",
        "outputId": "fe3217d5-5279-4a91-d555-1e7f419e44c2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "x_train = x_train.reshape(-1,1)\n",
        "\n",
        "x_train.shape"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OHlDlF8BpZcS"
      },
      "source": [
        "**Create a list of y values:**\n",
        "\n",
        "We want y values for every x value we have above.\n",
        "\n",
        "$y = 2x + 1$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NhMvknrNpLi0",
        "outputId": "3b16119d-1278-4c8b-8f7f-9bc6045a22ec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "y = [(2*i+1) for i in x]\n",
        "\n",
        "y"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8J_0RAHTqAeJ"
      },
      "source": [
        "**Convert it into NumPy Array and reshape to 2D:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LUqwghAbpQOm",
        "outputId": "5ca4e4e4-0311-41c0-d70d-31e28cd37ada",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "y_train = np.array(y,dtype= np.float32)\n",
        "\n",
        "y_train = y_train.reshape(-1,1)\n",
        "\n",
        "y_train.shape"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EGGzGynlqYnn"
      },
      "source": [
        "### Building a Model:\n",
        "\n",
        "**Create Model:**\n",
        "\n",
        "1. Linear model\n",
        "    - True Equation: $y = 2x + 1$\n",
        "2. Forward\n",
        "    - Example\n",
        "        - Input $x = 1$\n",
        "        - Output $\\hat y = ?$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "itwYCe2uqLBs"
      },
      "source": [
        "class LinearRegression(nn.Module):\n",
        "  def __init__(self,input_dim, output_dim):\n",
        "    super(LinearRegression, self).__init__()\n",
        "    self.linear = nn.Linear(input_dim, output_dim)\n",
        "  \n",
        "  def forward(self, x):\n",
        "    out = self.linear(x)\n",
        "    return out"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_-Luu1y_sT6E"
      },
      "source": [
        "**Insantiate Model class**:\n",
        "\n",
        "- input: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
        "- desired output: [1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "osNiKsq8r9_p"
      },
      "source": [
        "input_dim = 1\n",
        "output_dim = 1\n",
        "\n",
        "model = LinearRegression(input_dim, output_dim)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z92BudhIsmOz"
      },
      "source": [
        "**Insantiate Loss class**\n",
        "\n",
        "- MSE Loss: Mean Squared Error\n",
        "- MSE = $\\frac{1}{n} \\sum_{i=1}^n(\\hat y_i - y_i)^2$\n",
        "    - $\\hat y$: prediction\n",
        "    - $y$: true value"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LhsUhdjysjZJ"
      },
      "source": [
        "criterion = nn.MSELoss()"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3DqdWvlst56g"
      },
      "source": [
        "**Instantiate Optimizer Class:**\n",
        "\n",
        "- Simplified equation\n",
        "    - $\\theta = \\theta - \\eta \\cdot \\nabla_\\theta$\n",
        "        - $\\theta:$ parameters (our variables)\n",
        "        - $\\eta$: learning rate (how fast we want to learn)\n",
        "        - $\\nabla_\\theta$: parameters' gradients\n",
        "- Even simplier equation\n",
        "    - `parameters = parameters - learning_rate * parameters_gradients`\n",
        "        - parameters: $\\alpha$ and $\\beta$ in $y = \\alpha x + \\beta$\n",
        "        - desired parameters: $\\alpha = 2$ and $\\beta = 1$ in $y = 2x + 1$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uPdMHtbOs_oY"
      },
      "source": [
        "learning_rate = 0.01\n",
        "\n",
        "optim = torch.optim.SGD(model.parameters(), lr = learning_rate)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jP4y1j0mvW6n"
      },
      "source": [
        "### Train a Model:\n",
        "\n",
        "1 epoch: going through the whole x_train data once\n",
        "\n",
        "- 100 epochs:\n",
        "    - 100x mapping `x_train = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]`\n",
        "- **Process:**\n",
        "    1. Convert inputs/labels into tensors with gradients.\n",
        "    2. Clear Gradient Buffers.\n",
        "    3. Get outputs from given inputs.\n",
        "    4. Get the Loss.\n",
        "    5. Get Gradients w.r.t the Parameters.\n",
        "    6. Update the Parameters using Gradiens.\n",
        "\n",
        "        `parameters = parameters - learning_rate * parameters_gradients`\n",
        "\n",
        "    7. Repeat\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FSFJaPQWw70u"
      },
      "source": [
        "**Use GPU for the model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Go6tFixuw6Sj"
      },
      "source": [
        "#device = torch.device('cuda' if torch.cuda.is_available else 'cpu')\n",
        "#model.to(device)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H4Ot_6YPt6lM",
        "outputId": "8d50c311-9b02-4bc9-b8c1-47d33d361074",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "epochs = 100\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  epoch+=1\n",
        "\n",
        "  # Convert numpt variable into tensor with gradients\n",
        "  # inputs = torch.from_numpy(x_train).to(device)\n",
        "  # labels = torch.from_numpy(y_train).to(device)\n",
        "\n",
        "  inputs = torch.from_numpy(x_train).requires_grad_()\n",
        "  labels = torch.from_numpy(y_train)\n",
        "\n",
        "  # clear the gradients w.r.t Paramters.\n",
        "  optim.zero_grad()\n",
        "\n",
        "  # Forward to get output:\n",
        "  output = model(inputs)\n",
        "\n",
        "  # Calcualte the loss\n",
        "  loss = criterion(output, labels)\n",
        "\n",
        "  # Getting Gradients w.r.t Parameters.\n",
        "  loss.backward()\n",
        "\n",
        "  # Update the Parameters.\n",
        "  optim.step()\n",
        "\n",
        "  # Logging\n",
        "  print('epoch {}, loss {}'.format(epoch, loss.item()))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch 1, loss 47.88352966308594\n",
            "epoch 2, loss 3.9125266075134277\n",
            "epoch 3, loss 0.32587307691574097\n",
            "epoch 4, loss 0.03324589878320694\n",
            "epoch 5, loss 0.009302987717092037\n",
            "epoch 6, loss 0.007276371121406555\n",
            "epoch 7, loss 0.007038334384560585\n",
            "epoch 8, loss 0.00694690179079771\n",
            "epoch 9, loss 0.006868313532322645\n",
            "epoch 10, loss 0.00679154135286808\n",
            "epoch 11, loss 0.006715713068842888\n",
            "epoch 12, loss 0.006640678737312555\n",
            "epoch 13, loss 0.006566544994711876\n",
            "epoch 14, loss 0.006493210792541504\n",
            "epoch 15, loss 0.00642069848254323\n",
            "epoch 16, loss 0.006348979193717241\n",
            "epoch 17, loss 0.006278103217482567\n",
            "epoch 18, loss 0.006207993254065514\n",
            "epoch 19, loss 0.0061386870220303535\n",
            "epoch 20, loss 0.006070141214877367\n",
            "epoch 21, loss 0.006002355832606554\n",
            "epoch 22, loss 0.005935305263847113\n",
            "epoch 23, loss 0.005869037937372923\n",
            "epoch 24, loss 0.005803501699119806\n",
            "epoch 25, loss 0.0057387021370232105\n",
            "epoch 26, loss 0.005674609448760748\n",
            "epoch 27, loss 0.0056112646125257015\n",
            "epoch 28, loss 0.005548568908125162\n",
            "epoch 29, loss 0.005486613139510155\n",
            "epoch 30, loss 0.0054253642447292805\n",
            "epoch 31, loss 0.005364785902202129\n",
            "epoch 32, loss 0.0053048827685415745\n",
            "epoch 33, loss 0.005245643202215433\n",
            "epoch 34, loss 0.005187066737562418\n",
            "epoch 35, loss 0.005129147320985794\n",
            "epoch 36, loss 0.005071843974292278\n",
            "epoch 37, loss 0.005015204660594463\n",
            "epoch 38, loss 0.004959212616086006\n",
            "epoch 39, loss 0.004903822671622038\n",
            "epoch 40, loss 0.004849083721637726\n",
            "epoch 41, loss 0.004794912412762642\n",
            "epoch 42, loss 0.004741386044770479\n",
            "epoch 43, loss 0.004688436631113291\n",
            "epoch 44, loss 0.004636077210307121\n",
            "epoch 45, loss 0.004584307782351971\n",
            "epoch 46, loss 0.004533131141215563\n",
            "epoch 47, loss 0.004482492338865995\n",
            "epoch 48, loss 0.004432434216141701\n",
            "epoch 49, loss 0.004382932558655739\n",
            "epoch 50, loss 0.004333994816988707\n",
            "epoch 51, loss 0.004285604227334261\n",
            "epoch 52, loss 0.004237750079482794\n",
            "epoch 53, loss 0.004190410487353802\n",
            "epoch 54, loss 0.004143623635172844\n",
            "epoch 55, loss 0.004097354132682085\n",
            "epoch 56, loss 0.004051597323268652\n",
            "epoch 57, loss 0.0040063317865133286\n",
            "epoch 58, loss 0.003961623180657625\n",
            "epoch 59, loss 0.003917372785508633\n",
            "epoch 60, loss 0.003873626934364438\n",
            "epoch 61, loss 0.0038303842302411795\n",
            "epoch 62, loss 0.0037876099813729525\n",
            "epoch 63, loss 0.003745333757251501\n",
            "epoch 64, loss 0.003703494556248188\n",
            "epoch 65, loss 0.003662143601104617\n",
            "epoch 66, loss 0.0036212352570146322\n",
            "epoch 67, loss 0.003580808872357011\n",
            "epoch 68, loss 0.003540800651535392\n",
            "epoch 69, loss 0.003501276718452573\n",
            "epoch 70, loss 0.003462179098278284\n",
            "epoch 71, loss 0.003423519665375352\n",
            "epoch 72, loss 0.0033852721098810434\n",
            "epoch 73, loss 0.00334748113527894\n",
            "epoch 74, loss 0.003310119267553091\n",
            "epoch 75, loss 0.00327315554022789\n",
            "epoch 76, loss 0.003236587392166257\n",
            "epoch 77, loss 0.0032004325184971094\n",
            "epoch 78, loss 0.003164703492075205\n",
            "epoch 79, loss 0.003129368182271719\n",
            "epoch 80, loss 0.003094407031312585\n",
            "epoch 81, loss 0.00305985938757658\n",
            "epoch 82, loss 0.0030256875324994326\n",
            "epoch 83, loss 0.002991895889863372\n",
            "epoch 84, loss 0.0029584961012005806\n",
            "epoch 85, loss 0.002925445791333914\n",
            "epoch 86, loss 0.0028927826788276434\n",
            "epoch 87, loss 0.002860488835722208\n",
            "epoch 88, loss 0.002828555181622505\n",
            "epoch 89, loss 0.002796970074996352\n",
            "epoch 90, loss 0.0027657262980937958\n",
            "epoch 91, loss 0.002734833164140582\n",
            "epoch 92, loss 0.0027043025474995375\n",
            "epoch 93, loss 0.002674124436452985\n",
            "epoch 94, loss 0.002644235035404563\n",
            "epoch 95, loss 0.0026147139724344015\n",
            "epoch 96, loss 0.0025855174753814936\n",
            "epoch 97, loss 0.0025566373951733112\n",
            "epoch 98, loss 0.002528091659769416\n",
            "epoch 99, loss 0.0024998446460813284\n",
            "epoch 100, loss 0.00247191172093153\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sg378skRyrpg"
      },
      "source": [
        "**Looking at the Predicted values**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jMPF4BQYxTgM",
        "outputId": "71668371-baf9-4eab-ac18-c781e0b476ab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Purely inference\n",
        "predicted = model(torch.from_numpy(x_train).requires_grad_()).data.numpy()\n",
        "predicted"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1.0924866],\n",
              "       [ 3.0791678],\n",
              "       [ 5.065849 ],\n",
              "       [ 7.0525303],\n",
              "       [ 9.039211 ],\n",
              "       [11.025892 ],\n",
              "       [13.012573 ],\n",
              "       [14.999254 ],\n",
              "       [16.985935 ],\n",
              "       [18.972618 ],\n",
              "       [20.9593   ]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b5o7CJU1zVrL"
      },
      "source": [
        "**Plot of Predicted and Actual Values:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B_CSFNtSy9T0",
        "outputId": "fd26fcdc-0097-4988-b281-394c0e66cb40",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "# Clear Figure:\n",
        "plt.clf()\n",
        "\n",
        "# Plot True Data\n",
        "plt.plot(x_train, y_train, 'go', label = 'True Data', alpha = 0.5)\n",
        "\n",
        "# PLot predictions\n",
        "plt.plot(x_train, predicted, '--', label = 'Predictions', alpha = 0.5)\n",
        "\n",
        "# Legend and plot\n",
        "plt.legend(loc = 'best')\n",
        "plt.show()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Qu1H3681QNT"
      },
      "source": [
        "**Save Model:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YuEVOHLgziKs"
      },
      "source": [
        "save_model = False\n",
        "if save_model is True:\n",
        "  # Saves only parameters\n",
        "    # alpha & beta\n",
        "    torch.save(model.state_dict(),'model.pkl')"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pm-F7TRu1g4x"
      },
      "source": [
        "**Load Model:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tuAJcdW51gHs"
      },
      "source": [
        "load_model = False\n",
        "if load_model is True:\n",
        "  model.load_state_dict(torch.load('model.pkl'))"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dUuTt6nJ15eY"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "* Simple linear regression basics\n",
        "  * y = Ax + B\n",
        "  * y = 2x + 1\n",
        "* Example of simple linear regression\n",
        "* Aim of linear regression\n",
        "  * Minimizing distance between the points and the line\n",
        "    * Calculate \"distance\" through `MSE`\n",
        "    * Calculate `gradients`\n",
        "    * Update parameters with `parameters = parameters - learning_rate * gradients`\n",
        "    * Slowly update parameters A and B model the linear relationship between y and x of the form y = 2x + 1\n",
        "* Built a linear regression model in CPU and GPU\n",
        "  * Step 1: Create Model Class\n",
        "  * Step 2: Instantiate Model Class\n",
        "  * Step 3: Instantiate Loss Class\n",
        "  * Step 4: Instantiate Optimizer Class\n",
        "  * Step 5: Train Model\n",
        "* Important things to be on GPU\n",
        "  * model\n",
        "  * tensors with gradients\n",
        "* How to bring to GPU?\n",
        "  * `model_name.to(device)`\n",
        "  * `variable_name.to(device`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dKg6HAEr44Y2"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}